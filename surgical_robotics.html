<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Surgical Robotics | Raquel Susko</title>
  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
  <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
</head>
<body>
  <header>
    <h1>Surgical Robotics Research</h1>
    <p>Johns Hopkins University | Laboratory for Computational Sensing and Robotics (LCSR)</p>
  </header>

  <nav>
    <a href="index.html">Home</a>
    <a href="lens_lab.html">LENS Lab</a>
    <a href="surgical_robotics.html">Surgical Robotics</a>
    <a href="drone.html">DRONE</a>
    <a href="auv.html">AUV</a>
    <a href="biosensor.html">Biosensor</a>
  </nav>

  <div class="container">
    <section>
      <h2>System Overview: Haptic Teleoperation for Partial Nephrectomy</h2>
      <p>
        During my REU at the <strong>Imerse Lab</strong>, I developed a ROS 2-based teleoperation system designed for high-precision surgical tasks. The system enables intuitive control of a <strong>UR5 robotic arm</strong> using <strong>Force Dimension haptic devices</strong>, specifically optimized for partial nephrectomy procedures.
      </p>
      <p>
        My primary contribution focused on the <code>haptic_translator_trial_pkg</code>, where I engineered the translation layer between human input and robotic action, ensuring surgical-grade precision through PID-enhanced trajectory smoothing.
      </p>
    </section>

    <section>
      <h2>Core Features & Implementation</h2>
      <ul>
        <li><strong>6-DOF Teleoperation:</strong> Developed 1:1 position and orientation mapping between the Force Dimension device (Omega.7) and the UR5 TCP.</li>
        <li><strong>Multi-Modal Interface:</strong> Integrated a 3-pedal foot interface to manage critical surgical states: clutch control (movement enable), vacuum gripper activation, and automated data recording.</li>
        <li><strong>PID Control:</strong> Implemented trajectory smoothing algorithms to minimize jitter and enhance precision during delicate tissue manipulation.</li>
        <li><strong>Hardware Integration:</strong> Managed a complex stack including <strong>Zivid 3D cameras</strong>, <strong>Robotiq vacuum grippers</strong>, and <strong>Spinnaker camera drivers</strong> within a unified ROS 2 Humble environment.</li>
      </ul>
    </section>

    <section>
      <h2>Data Pipeline for Imitation Learning</h2>
      <p>
        A critical goal of the system was generating high-fidelity datasets for machine learning. I designed a robust data recording node that captures synchronized observations and actions.
      </p>
      <div style="display: flex; gap: 20px; flex-wrap: wrap; margin-top: 20px;">
        <div style="flex: 1; min-width: 250px; background: #f1f5f9; padding: 20px; border-radius: 8px;">
          <h4 style="margin-top: 0; color: var(--secondary);">Observations Recorded</h4>
          <ul style="font-size: 0.85rem; padding-left: 20px;">
            <li>6-DOF Robot Poses & Velocities</li>
            <li>Joint-level positions/velocities</li>
            <li>RGB-D Point Clouds (Zivid/Spinnaker)</li>
            <li>Haptic Device state feedback</li>
          </ul>
        </div>
        <div style="flex: 1; min-width: 250px; background: #f1f5f9; padding: 20px; border-radius: 8px;">
          <h4 style="margin-top: 0; color: var(--secondary);">Actions Recorded</h4>
          <ul style="font-size: 0.85rem; padding-left: 20px;">
            <li>Commanded Target Poses</li>
            <li>Vacuum Gripper activation states</li>
            <li>Foot pedal toggle events</li>
            <li>Low-level motion parameters</li>
          </ul>
        </div>
      </div>
      <p style="margin-top: 20px;">
        Data is simultaneously exported to <strong>ROS Bags (.db3)</strong> for visual playback and <strong>Pickle files (.pkl)</strong> for direct ingestion into ML training pipelines.
      </p>
    </section>

    <section>
      <h2>Project Repository</h2>
      <p>The full implementation of the teleoperation nodes, foot pedal interfaces, and data recorder can be found here:</p>
      <a href="https://github.com/raquelsusko/JHU_Teleop" class="button" target="_blank">
        <i class="fab fa-github"></i> View JHU_Teleop on GitHub
      </a>
    </section>
  </div>

  <footer>
    &copy; 2026 Raquel Susko | Johns Hopkins University REU
  </footer>
</body>
</html>